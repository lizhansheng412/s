# JSONL批量更新器 V5 - 增量更新机制说明

## 问题背景

在批次2执行后，发现大量 `{"corpusid":xxx, "title":""}` 的情况，title字段为空。

## 问题根因

**原代码存在覆盖bug：**

批次2-3在处理时，会**完全重新构造**citations/references列表，导致前面批次已经填充的title被当前批次的空title覆盖。

### 错误流程示例

```python
# 批次1处理后的数据
{
  "corpusid": 100,
  "citations": [
    {"corpusid": 50, "title": "Paper A"},      # ✓ 批次1填充
    {"corpusid": 500, "title": ""},            # ✗ 不在批次1范围
    {"corpusid": 90000000, "title": ""}        # ✗ 不在批次1范围
  ]
}

# 批次2处理时（错误逻辑）
citations_data = [{"corpusid":50, "title":"Paper A"}, {"corpusid":500, "title":""}, ...]

# ❌ 提取corpusid，丢弃原有title
citations_ids = [50, 500, 90000000]

# ❌ 重新构造，导致覆盖
for cid in citations_ids:
    title = title_cache.get(cid, "")  # 50不在批次2范围 → ""
    citations_full.append({"corpusid": cid, "title": title})  # ❌ "Paper A" 被覆盖成 ""

# 批次2处理后（错误结果）
{
  "corpusid": 100,
  "citations": [
    {"corpusid": 50, "title": ""},             # ❌ 被覆盖成空了！
    {"corpusid": 500, "title": "Paper B"},     # ✓ 批次2填充
    {"corpusid": 90000000, "title": ""}        # ✗ 不在批次2范围
  ]
}
```

## 解决方案

**关键修复点：保留原有数据结构，只更新空title**

```python
# 批次2处理时（正确逻辑）
citations_data = [{"corpusid":50, "title":"Paper A"}, {"corpusid":500, "title":""}, ...]

# ✓ 直接保留原有的完整对象
citations_full = citations_data.copy()

# ✓ 只更新空title，跳过非空title
for item in citations_full:
    cid = item['corpusid']
    if not item['title']:  # 只处理空title
        title = title_cache.get(cid, "")
        if title:
            item['title'] = title  # 只填充找到的title

# 批次2处理后（正确结果）
{
  "corpusid": 100,
  "citations": [
    {"corpusid": 50, "title": "Paper A"},      # ✓ 保留批次1的结果
    {"corpusid": 500, "title": "Paper B"},     # ✓ 批次2填充
    {"corpusid": 90000000, "title": ""}        # ✗ 等待批次3
  ]
}
```

## 增量更新机制

### 批次1
- **读取**：`E:/copy_final_1/*.jsonl`（快速模式：`[corpusid列表]`）
- **处理**：转换为完整模式 `[{corpusid, title}对象]`
- **填充**：前1/3范围的title（按OFFSET/LIMIT切分）
- **输出**：`E:/copy_final_cache/*.jsonl`

### 批次2
- **读取**：`E:/copy_final_cache/*.jsonl`（批次1的完整模式文件）
- **处理**：保留原有对象结构（`citations_full = citations_data.copy()`）
- **填充**：只更新空title（`if not item['title']`）
- **输出**：原地更新（临时文件覆盖）

### 批次3
- **读取**：`E:/copy_final_cache/*.jsonl`（批次2更新后的文件）
- **处理**：继续保留已有title
- **填充**：填充剩余空title
- **输出**：原地更新

## 关键代码改动

### 改动1：保留原有数据结构（第241-254行）

```python
# 判断数据格式并保留原有数据（避免覆盖已填充的title）
if citations_data and isinstance(citations_data[0], dict):
    # ✓ 已经是完整模式（批次2-3），保留原有的完整对象
    citations_full = citations_data.copy()
else:
    # 快速模式（批次1），转换为对象列表
    citations_full = [{"corpusid": cid, "title": ""} for cid in citations_data]
```

### 改动2：只更新空title（第260-268行）

```python
# 只处理title为空的corpusid，跳过已有title的记录
for item in citations_full:
    cid = item['corpusid']
    # ✓ 检查title是否为空：为空则尝试填充，不为空则跳过
    if not item['title']:
        title = self.title_cache.get(cid, "")
        if title:
            item['title'] = title
            updated_titles += 1
    # else: title不为空，说明前面批次已处理过，直接跳过
```

## 验证方法

运行批次2后，检查输出文件：

```bash
# 随机抽取一个文件查看
head -1 E:/copy_final_cache/0.jsonl | python -m json.tool
```

**预期结果：**
- citations/references中既有批次1填充的title（非空）
- 也有批次2新填充的title（非空）
- 批次1填充的title不会被覆盖成空字符串

## 运行命令

```bash
# 批次2（增量更新）
python batch_update/jsonl_batch_updater_v5.py --batch 2

# 批次3（继续增量更新）
python batch_update/jsonl_batch_updater_v5.py --batch 3
```

## 核心优势

✅ **避免覆盖**：通过 `if not item['title']` 检查，跳过已有title  
✅ **内存高效**：每次只加载1/3的title数据  
✅ **可中断恢复**：每批次独立运行，可随时停止和继续  
✅ **数据完整**：3个批次完成后，所有corpusid的title都被填充

