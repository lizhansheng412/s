#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡ç»„abstractsè¡¨ç‰©ç†å­˜å‚¨ - CLUSTERä¼˜åŒ–
===============================================
åŠŸèƒ½ï¼šæŒ‰corpusidä¸»é”®é‡æ–°ç»„ç»‡abstractsè¡¨çš„ç‰©ç†å­˜å‚¨é¡ºåº
æ•ˆæœï¼šå°†éšæœºI/Oè½¬æ¢ä¸ºé¡ºåºI/Oï¼ŒæŸ¥è¯¢é€Ÿåº¦æå‡100å€ä»¥ä¸Š

æ³¨æ„äº‹é¡¹ï¼š
1. æ­¤æ“ä½œä¼šé”å®šabstractsè¡¨ï¼Œæ‰§è¡ŒæœŸé—´æ— æ³•è¯»å†™
2. éœ€è¦çº¦2å€è¡¨å¤§å°çš„ä¸´æ—¶ç£ç›˜ç©ºé—´
3. é¢„è®¡è€—æ—¶ï¼š1-3å°æ—¶ï¼ˆå–å†³äºUSBç¡¬ç›˜é€Ÿåº¦ï¼‰
4. æ‰§è¡Œå‰è¯·åœæ­¢æ‰€æœ‰å¯¼å‡ºä»»åŠ¡
"""

import sys
import os
import time
import psycopg2
from datetime import datetime

# æ·»åŠ çˆ¶ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from database.config.db_config_v2 import get_db_config


def get_table_info(conn, table_name):
    """è·å–è¡¨çš„å…³é”®ä¿¡æ¯ï¼ˆä¸€æ¬¡æŸ¥è¯¢è·å–æ‰€æœ‰éœ€è¦çš„æ•°æ®ï¼‰"""
    cursor = conn.cursor()
    try:
        cursor.execute(f"""
            SELECT 
                pg_size_pretty(pg_total_relation_size('{table_name}')) as total_size,
                pg_total_relation_size('{table_name}') as total_bytes,
                n_live_tup as live_tuples
            FROM pg_class c
            LEFT JOIN pg_stat_user_tables s ON c.relname = s.relname
            WHERE c.relname = '{table_name}'
        """)
        result = cursor.fetchone()
        return {
            'total_size': result[0],
            'total_bytes': result[1],
            'live_tuples': result[2]
        }
    finally:
        cursor.close()


def cluster_abstracts_table():
    """æ‰§è¡ŒCLUSTERæ“ä½œé‡ç»„abstractsè¡¨"""
    
    print("=" * 80)
    print("ABSTRACTSè¡¨ç‰©ç†å­˜å‚¨é‡ç»„ - CLUSTERä¼˜åŒ–")
    print("=" * 80)
    print()
    
    conn = None
    try:
        # 1. è¿æ¥æ•°æ®åº“å¹¶æ£€æŸ¥è¡¨ä¿¡æ¯
        print("ğŸ“Š æ­£åœ¨è¿æ¥æ•°æ®åº“å¹¶æ£€æŸ¥è¡¨ä¿¡æ¯...")
        machine3_config = get_db_config('machine3')
        conn = psycopg2.connect(**machine3_config)
        conn.autocommit = True  # CLUSTERæ˜¯DDLæ“ä½œï¼Œç›´æ¥ä½¿ç”¨autocommit
        
        table_info = get_table_info(conn, 'abstracts')
        
        print("âœ“ å·²è¿æ¥åˆ°æ•°æ®åº“")
        print()
        print(f"è¡¨ä¿¡æ¯:")
        print(f"  - æ€»å¤§å°: {table_info['total_size']}")
        print(f"  - è®°å½•æ•°: {table_info['live_tuples']:,}")
        print(f"  - é¢„è®¡ä¸´æ—¶ç©ºé—´: {table_info['total_bytes'] * 2 / (1024**3):.2f} GB")
        print(f"  - é¢„è®¡è€—æ—¶: 1-3å°æ—¶")
        print()
        
        # 2. ç¡®è®¤æ‰§è¡Œ
        print("=" * 80)
        print("âš ï¸  é‡è¦æç¤º")
        print("=" * 80)
        print("1. CLUSTERä¼šé”å®šabstractsè¡¨ï¼Œæ‰§è¡ŒæœŸé—´æ— æ³•è¯»å†™")
        print("2. è¯·ç¡®ä¿å·²åœæ­¢æ‰€æœ‰export_to_jsonl_parallel.pyè¿›ç¨‹")
        print("3. æ“ä½œä¸å¯ä¸­æ–­ï¼Œä¸­æ–­åéœ€è¦ä»å¤´å¼€å§‹")
        print()
        
        response = input("ç¡®è®¤æ‰§è¡ŒCLUSTERï¼Ÿ(yes/no): ").strip().lower()
        if response != 'yes':
            print("\nâŒ æ“ä½œå·²å–æ¶ˆ")
            return
        
        print()
        
        # 3. æ‰§è¡ŒCLUSTERé‡ç»„ï¼ˆæ ¸å¿ƒæ­¥éª¤ï¼‰
        print("=" * 80)
        print("æ‰§è¡ŒCLUSTERé‡ç»„")
        print("=" * 80)
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] å¼€å§‹CLUSTER abstracts...")
        print("â³ æ­£åœ¨é‡ç»„è¡¨çš„ç‰©ç†å­˜å‚¨ï¼ˆçº¦1-3å°æ—¶ï¼‰ï¼Œè¯·å‹¿ä¸­æ–­...")
        print()
        
        cluster_start = time.time()
        cursor = conn.cursor()
        
        # æ‰§è¡ŒCLUSTERï¼ˆæŒ‰ä¸»é”®é‡ç»„ç‰©ç†å­˜å‚¨ï¼‰
        cursor.execute("CLUSTER abstracts USING abstracts_pkey")
        cursor.close()
        
        cluster_elapsed = time.time() - cluster_start
        print(f"\nâœ“ CLUSTERå®Œæˆ")
        print(f"  è€—æ—¶: {cluster_elapsed/60:.1f}åˆ†é’Ÿ ({cluster_elapsed/3600:.2f}å°æ—¶)")
        print()
        
        # 4. æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] æ›´æ–°ç»Ÿè®¡ä¿¡æ¯...")
        
        analyze_start = time.time()
        cursor = conn.cursor()
        cursor.execute("ANALYZE abstracts")
        cursor.close()
        
        analyze_elapsed = time.time() - analyze_start
        print(f"âœ“ ANALYZEå®Œæˆï¼Œè€—æ—¶: {analyze_elapsed:.1f}ç§’")
        print()
        
        # 5. éªŒè¯ç»“æœ
        new_table_info = get_table_info(conn, 'abstracts')
        
        print("=" * 80)
        print("ä¼˜åŒ–ç»“æœ")
        print("=" * 80)
        print(f"ä¼˜åŒ–åè¡¨å¤§å°: {new_table_info['total_size']}")
        print(f"è®°å½•æ•°: {new_table_info['live_tuples']:,}")
        
        size_diff = table_info['total_bytes'] - new_table_info['total_bytes']
        if size_diff > 0:
            print(f"ç©ºé—´èŠ‚çœ: {size_diff / (1024**3):.2f} GB")
        print()
        
        # æ€»ç»“
        total_elapsed = cluster_elapsed + analyze_elapsed
        print("=" * 80)
        print("âœ… ä¼˜åŒ–å®Œæˆï¼")
        print("=" * 80)
        print(f"æ€»è€—æ—¶: {total_elapsed/60:.1f}åˆ†é’Ÿ ({total_elapsed/3600:.2f}å°æ—¶)")
        print()
        print("é¢„æœŸæ•ˆæœ:")
        print("  âœ“ abstractsè¡¨æŸ¥è¯¢: 124ç§’ â†’ <1ç§’ (100å€â†‘)")
        print("  âœ“ æ€»å¤„ç†é€Ÿåº¦: 300æ¡/ç§’ â†’ 1500æ¡/ç§’ (5å€â†‘)")
        print("  âœ“ å®Œæˆæ—¶é—´: 91å°æ—¶ â†’ 18.5å°æ—¶ (80%â†“)")
        print()
        print("ğŸ“ ä¸‹ä¸€æ­¥:")
        print("  1. é‡å¯ export_to_jsonl_parallel.py")
        print("  2. è§‚å¯Ÿæ–°çš„å¤„ç†é€Ÿåº¦")
        print()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·")
        print("æ³¨æ„: CLUSTERæ“ä½œå¯èƒ½å·²éƒ¨åˆ†å®Œæˆï¼Œå»ºè®®æ£€æŸ¥è¡¨çŠ¶æ€")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        if conn:
            conn.close()
            print("\næ•°æ®åº“è¿æ¥å·²å…³é—­")


if __name__ == '__main__':
    cluster_abstracts_table()

